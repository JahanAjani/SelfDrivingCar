{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks in keras\n",
    "\n",
    "<p>\n",
    "    Keras is built upon tensorflow API's. Keras provides easy to use API's which abtracts major part of model building in tensorflow, thus provide fast prototyping.\n",
    "<p>\n",
    "    Unlike in tensorflow, where you have to provide input dimension as well as output dimensions and perform dot product of weight and input data, keras handles all this and provide you nice wrapper around it. So, let's dive in to build our first keras model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load traffic sign small data set\n",
    "\n",
    "training_file = \"./dataset/traffic/small_traffic_set/small_train_traffic.p\"\n",
    "test_file = \"./dataset/traffic/small_traffic_set/small_test_traffic.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(test_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - np.mean(X_train))/np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - np.mean(X_test))/np.std(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train examples: 100\n",
      "input image shape: (32, 32, 3)\n",
      "classes: 5\n",
      "[2 2 3 2 4 3 3 3 1 4 2 4 2 5 1 4 5 1 1 1 4 2 1 4 5 3 4 1 3 4 4 5 5 1 4 5 2\n",
      " 5 1 5 3 5 2 2 1 3 5 5 4 2 5 4 3 3 2 5 3 2 3 3 1 5 5 2 1 2 2 2 4 1 5 4 4 5\n",
      " 5 3 1 3 4 3 4 4 5 2 4 1 3 5 4 4 2 5 1 1 2 3 1 3 1 4]\n",
      "num of test examples: 20\n",
      "input image shape: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "num_examples, h, w, c = X_train.shape\n",
    "n_classes  = len(np.unique(y_train))\n",
    "print(\"num of train examples: {}\".format(num_examples))\n",
    "print(\"input image shape: {}\".format((h,w,c)))\n",
    "print(\"classes: {}\".format(n_classes))\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "h, w, c = X_test[0].shape\n",
    "print(\"num of test examples: {}\".format(len(X_test)))\n",
    "print(\"input image shape: {}\".format((h,w,c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "print(y_train_cat[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins = np.histogram(y_train, bins=n_classes)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_for_LabelBinarizer():\n",
    "    # create the Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    #1st Layer - Add a flatten layer\n",
    "    model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "\n",
    "    #2nd Layer - Add a fully connected layer\n",
    "    model.add(Dense(100))\n",
    "\n",
    "    #3rd Layer - Add a ReLU activation layer\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #4th Layer - Add a fully connected layer\n",
    "    model.add(Dense(5))\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def keras_model_for_to_categorical():\n",
    "    # create the Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    #1st Layer - Add a flatten layer\n",
    "    model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "\n",
    "    #2nd Layer - Add a fully connected layer\n",
    "    model.add(Dense(100))\n",
    "\n",
    "    #3rd Layer - Add a ReLU activation layer\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #4th Layer - Add a fully connected layer\n",
    "    model.add(Dense(6))\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_29 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 6)                 606       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 307,906\n",
      "Trainable params: 307,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras_model_for_to_categorical()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile('sgd', 'mean_squared_error', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/11\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.9904 - acc: 0.1714 - val_loss: 0.9374 - val_acc: 0.5000\n",
      "Epoch 2/11\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.7392 - acc: 0.5714 - val_loss: 0.9036 - val_acc: 0.5667\n",
      "Epoch 3/11\n",
      "70/70 [==============================] - 0s 172us/step - loss: 0.6878 - acc: 0.6571 - val_loss: 1.2757 - val_acc: 0.6000\n",
      "Epoch 4/11\n",
      "70/70 [==============================] - 0s 158us/step - loss: 1.0794 - acc: 0.6714 - val_loss: 0.8477 - val_acc: 0.6333\n",
      "Epoch 5/11\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6896 - acc: 0.6857 - val_loss: 0.7722 - val_acc: 0.7000\n",
      "Epoch 6/11\n",
      "70/70 [==============================] - 0s 143us/step - loss: 0.5791 - acc: 0.7571 - val_loss: 0.6425 - val_acc: 0.7667\n",
      "Epoch 7/11\n",
      "70/70 [==============================] - 0s 185us/step - loss: 0.4633 - acc: 0.8143 - val_loss: 0.3517 - val_acc: 0.7667\n",
      "Epoch 8/11\n",
      "70/70 [==============================] - 0s 143us/step - loss: 0.2566 - acc: 0.8143 - val_loss: 0.4473 - val_acc: 0.7667\n",
      "Epoch 9/11\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.3666 - acc: 0.8143 - val_loss: 0.2021 - val_acc: 0.9667\n",
      "Epoch 10/11\n",
      "70/70 [==============================] - 0s 142us/step - loss: 0.1288 - acc: 0.9857 - val_loss: 0.3337 - val_acc: 0.8667\n",
      "Epoch 11/11\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.2147 - acc: 0.8714 - val_loss: 0.2844 - val_acc: 0.9333\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, to_categorical(y_train), batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.3)\n",
    "\n",
    "#history = model.fit(X_train, lb.transform(y_train), batch_size=128, epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20/20 [==============================] - 0s 150us/step\n"
     ]
    }
   ],
   "source": [
    "test_score = model.evaluate(X_test, to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc'] : [1.2720391750335693, 0.800000011920929]\n"
     ]
    }
   ],
   "source": [
    "print(str(model.metrics_names) + \" : \"+ str(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5], dtype=uint8)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y_train)\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_30 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 5)                 505       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 307,805\n",
      "Trainable params: 307,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/11\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 2.5690 - acc: 0.0143 - val_loss: 1.3212 - val_acc: 0.4667\n",
      "Epoch 2/11\n",
      "70/70 [==============================] - 0s 143us/step - loss: 1.0508 - acc: 0.5714 - val_loss: 1.1984 - val_acc: 0.5333\n",
      "Epoch 3/11\n",
      "70/70 [==============================] - 0s 171us/step - loss: 0.9967 - acc: 0.7000 - val_loss: 0.6039 - val_acc: 0.7333\n",
      "Epoch 4/11\n",
      "70/70 [==============================] - 0s 158us/step - loss: 0.4664 - acc: 0.7571 - val_loss: 0.7736 - val_acc: 0.7667\n",
      "Epoch 5/11\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.6568 - acc: 0.8000 - val_loss: 0.5998 - val_acc: 0.8000\n",
      "Epoch 6/11\n",
      "70/70 [==============================] - 0s 144us/step - loss: 0.5155 - acc: 0.8143 - val_loss: 0.3218 - val_acc: 0.8333\n",
      "Epoch 7/11\n",
      "70/70 [==============================] - 0s 171us/step - loss: 0.2701 - acc: 0.8143 - val_loss: 0.4332 - val_acc: 0.8000\n",
      "Epoch 8/11\n",
      "70/70 [==============================] - 0s 143us/step - loss: 0.3806 - acc: 0.8143 - val_loss: 0.2204 - val_acc: 0.9333\n",
      "Epoch 9/11\n",
      "70/70 [==============================] - 0s 143us/step - loss: 0.1815 - acc: 0.9714 - val_loss: 0.2905 - val_acc: 0.8000\n",
      "Epoch 10/11\n",
      "70/70 [==============================] - 0s 143us/step - loss: 0.2580 - acc: 0.8143 - val_loss: 0.2631 - val_acc: 0.8000\n",
      "Epoch 11/11\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.2345 - acc: 0.8143 - val_loss: 0.1573 - val_acc: 1.0000\n",
      "Evaluate on test data: \n",
      "20/20 [==============================] - 0s 150us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras_model_for_LabelBinarizer()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, lb.transform(y_train), batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.3)\n",
    "print(\"Evaluate on test data: \")\n",
    "test_score = model.evaluate(X_test, lb.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc'] : [2.1972899436950684, 0.8500000238418579]\n"
     ]
    }
   ],
   "source": [
    "print(str(model.metrics_names) + \" : \"+ str(test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdc",
   "language": "python",
   "name": "sdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
